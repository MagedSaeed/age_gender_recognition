{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Trial with PyVision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit: The original code for each section below is from the source the following source, however some modification is done to fit our purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: https://www.cs.colostate.edu/~cs510/yr2012/Progress/ProgressMedia/CSU_pyvision_Tutorial_CS510.pdf </br>\n",
    "http://bolme.github.io/pyvision_docs/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not import fast_util.\n"
     ]
    }
   ],
   "source": [
    "import pyvision as pv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an Image and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pv.Image(\"sl4.jpg\")\n",
    "im.show()\n",
    "cv2.destroyAllWindows() #This is just to close the image window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvision.face.CascadeDetector as cd\n",
    "im = pv.Image(\"img/face.png\")\n",
    "face_detector = cd.CascadeDetector() #This class is a wrapper around the OpenCV cascade detectior.\n",
    "#it returns faces collection since theree might be more than one face in the image.\n",
    "faces = face_detector(im)\n",
    "# or alternatively\n",
    "#faces = face_detector.detect(im)\n",
    "\n",
    "for face in faces:\n",
    "    im.annotatePolygon(face.asPolygon(), width=4)\n",
    "\n",
    "im.show(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvision.face.CascadeDetector as cd\n",
    "import pyvision.face.FilterEyeLocator as ed\n",
    "face_detect = cd.CascadeDetector()\n",
    "eye_detect = ed.FilterEyeLocator()\n",
    "im = pv.Image(\"img/me.jpg\",bw_annotate=True)\n",
    "faces = face_detect(im)\n",
    "eyes = eye_detect(im,faces)\n",
    "for face,eye1,eye2 in eyes:\n",
    "    im.annotatePolygon(face.asPolygon(), width=4)\n",
    "    im.annotatePoints([eye1,eye2])\n",
    "\n",
    "im.show(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvision.face.CascadeDetector as cd\n",
    "im = pv.Image(\"img/faceR.png\")\n",
    "face_detector = cd.CascadeDetector() #This class is a wrapper around the OpenCV cascade detectior.\n",
    "faces = face_detector(im)\n",
    "for face in faces:\n",
    "    affine = pv.AffineFromRect(rect=face, new_Size=(255,255), interpolate=2) \n",
    "    cim = affine.transformImage(im)\n",
    "    cim.show(delay=0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Rotation\n",
    "Image rotation is need because face detector will not work when the face is not in certain angle.\n",
    "\"Violaâ€“Jones requires full view frontal upright faces\". Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pv.Image(\"img/faceR.png\")\n",
    "affine = pv.AffineRotate(theta=-3.14/2, new_size=(im.height,im.width), center= pv.Point(im.height/2,im.width/2),interpolate=2) \n",
    "cim = affine.transformImage(im)\n",
    "cim.show(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[pv.Rect(83.076923,88.461538,186.923077,186.923077), pv.Point(138.569712,162.938702,0.000000), pv.Point(211.586538,162.938702,0.000000)]]\n"
     ]
    }
   ],
   "source": [
    "import pyvision.face.CascadeDetector as cd\n",
    "import pyvision.face.FilterEyeLocator as ed\n",
    "face_detect = cd.CascadeDetector()\n",
    "eye_detect = ed.FilterEyeLocator()\n",
    "\n",
    "im2 = pv.Image(\"img/me.jpg\")\n",
    "im1 = pv.Image(\"img/face.png\")\n",
    "\n",
    "faces1 = face_detect(im1)\n",
    "faces2 = face_detect(im2)\n",
    "print eye_detect(im1,faces1)\n",
    "face1,eye11,eye12 = eye_detect(im1,faces1)[0]\n",
    "face2,eye21,eye22 = eye_detect(im2,faces2)[0]\n",
    "\n",
    "\n",
    "affine = pv.AffineFromPoints(src1=eye11, src2=eye12, dst1=eye21, dst2=eye22, new_size=(im2.height,im2.width), interpolate=2)\n",
    "cim1 = affine.transformImage(im1,im2)\n",
    "cim1.show(delay=0)\n",
    "im2.show(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pv.Image(\"img/face.png\")\n",
    "affine = pv.AffineScale(scale=0.5,  new_size=(256,256),interpolate=2) \n",
    "cim = affine.transformImage(im)\n",
    "cim.show(delay=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Perturbation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly perturbs the image to generate more training images. images generated from this code should be used in the training with the same label of the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pv.Image(\"img/face.png\")\n",
    "\n",
    "for i in xrange(10):\n",
    "    affine = pv.AffinePerturb(Dscale =0.3, Drotate=0.56, Dtranslate=100, new_size=(256,256), mirror=False, flip=False, rng=None)\n",
    "    cim = affine.transformImage(im)\n",
    "    cv2.imwrite('img/face'+str(i)+'.png',cim.asOpenCV2())\n",
    "    \n",
    "# TODO we have to find out how to connect all the new image with the label of the original image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying all preprocessing techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can be found on pre.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
