{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2.cv as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This program is demonstration for face and object\n",
    "detection using haar-like features.\n",
    "The program finds faces in a camera image or video\n",
    "stream and displays a red box around them.\n",
    "Original C implementation by: ?\n",
    "Python implementation by: Roman Stanchak, James\n",
    "Bowman\n",
    "\"\"\"\n",
    "import sys\n",
    "from optparse import OptionParser\n",
    "# Parameters for haar detection\n",
    "# From the API:\n",
    "# The default parameters (scale_factor=2, min_neighbors=3, flags=0) are tuned\n",
    "# for accurate yet slow object detection. For a faster operation on real video\n",
    "# images the settings are:\n",
    "# scale_factor=1.2, min_neighbors=2,flags=CV_HAAR_DO_CANNY_PRUNING,\n",
    "# min_size=<minimum possible face size\n",
    "\n",
    "min_size = (20, 20)\n",
    "image_scale = 2\n",
    "haar_scale = 1.2\n",
    "min_neighbors = 2\n",
    "haar_flags = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_draw(img, cascade):\n",
    "    # allocate temporary images\n",
    "    gray = cv.CreateImage((img.width,img.height), 8,1)\n",
    "    small_img = cv.CreateImage((cv.Round(img.width/image_scale), cv.Round (img.height /image_scale)), 8, 1)\n",
    "    # convert color input image to grayscale\n",
    "    cv.CvtColor(img, gray, cv.CV_BGR2GRAY)\n",
    "    # scale input image for faster processing\n",
    "    cv.Resize(gray, small_img, cv.CV_INTER_LINEAR)\n",
    "    \n",
    "    cv.EqualizeHist(small_img, small_img)\n",
    "    \n",
    "    if(cascade):\n",
    "        t = cv.GetTickCount()\n",
    "        faces = cv.HaarDetectObjects(small_img, cascade, cv.CreateMemStorage(0), haar_scale,\n",
    "                                     min_neighbors, haar_flags, min_size)\n",
    "        t = cv.GetTickCount() - t\n",
    "        print \"detection time = %gms\" % (t/(cv.GetTickFrequency()*1000.))\n",
    "        if faces:\n",
    "            for ((x, y, w, h), n) in faces:\n",
    "                # the input to cv.HaarDetectObjects was resized, so scale the\n",
    "                # bounding box of each face and convert it to two CvPoints\n",
    "                pt1 = (int(x * image_scale), int(y *image_scale))\n",
    "                pt2 = (int((x + w) * image_scale),int((y + h) * image_scale))\n",
    "                cv.Rectangle(img, pt1, pt2, cv.RGB(255, 0, 0), 3, 8, 0)\n",
    "    cv.ShowImage(\"result\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection time = 1.267ms\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv2.cv as cv\n",
    "cascade = cv.Load(\"C:\\\\Python27\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_alt.xml\")\n",
    "image = cv.LoadImage(\"1.pgm\", 1)\n",
    "detect_and_draw(image, cascade)\n",
    "cv.WaitKey(0)\n",
    "cv.DestroyWindow(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"hello world\"\n",
    "    parser = OptionParser(usage = \"usage: %prog [options] [filename|camera_index]\")\n",
    "    parser.add_option(\"-c\", \"--cascade\", action=\"store\", dest=\"cascade\", type=\"str\",\n",
    "                      help=\"Haar cascade file, default %default\", \n",
    "                      default =\"../data/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "    (options, args) = parser.parse_args()\n",
    "    print \"load cascade\"\n",
    "    cascade = cv.Load(options.cascade)\n",
    "\n",
    "    print \"Print help\"\n",
    "    if len(args) != 1:\n",
    "        parser.print_help()\n",
    "        sys.exit(1)\n",
    "        \n",
    "    input_name = args[0]\n",
    "    print input_name\n",
    "    if input_name.isdigit():\n",
    "        capture = cv.CreateCameraCapture(int(input_name))\n",
    "    else:\n",
    "        capture = None\n",
    "        \n",
    "    cv.NamedWindow(\"result\", 1)\n",
    "    if capture:\n",
    "        frame_copy = None  \n",
    "\n",
    "    while True:\n",
    "        frame = cv.QueryFrame(capture)\n",
    "        if not frame:\n",
    "            cv.WaitKey(0)\n",
    "            break\n",
    "        if not frame_copy:\n",
    "            frame_copy = cv.CreateImage((frame.width,frame.height), cv.IPL_DEPTH_8U, frame.nChannels)\n",
    "        if frame.origin == cv.IPL_ORIGIN_TL:\n",
    "            cv.Copy(frame, frame_copy)\n",
    "        else:\n",
    "            cv.Flip(frame, frame_copy, 0)\n",
    "\n",
    "        detect_and_draw(frame_copy, cascade)\n",
    "        if cv.WaitKey(10) >= 0:\n",
    "            break\n",
    "else:\n",
    "    image = cv.LoadImage(\"1.pgm\", 1)\n",
    "    detect_and_draw(image, cascade)\n",
    "    cv.WaitKey(0)\n",
    "cv.DestroyWindow(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not import fast_util.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: A patent protection is anticipated for ASEF and \n",
      "             similar filters by the Colorado State University \n",
      "             Research Foundation (CSURF). \n",
      "       \n",
      "             This module, \"FilterEyeLocator.py\", my not be \n",
      "             suitable for commercial use.\n",
      "    \n",
      "             Commercial and government users should contact \n",
      "             CSURF for additional details:\n",
      "             http://www.csurf.org/tto/pdfs/ncs_forms/09-017_csurf_ncs.pdf\n",
      "    "
     ]
    }
   ],
   "source": [
    "import pyvision as pv\n",
    "import pyvision.face.CascadeDetector as cd\n",
    "import pyvision.face.FilterEyeLocator as ed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detect = cd.CascadeDetector()\n",
    "eye_detect = ed.FilterEyeLocator()\n",
    "im = pv.Image(\"1.pgm\",bw_annotate=True)\n",
    "faces = face_detect(im)\n",
    "eyes = eye_detect(im,faces)\n",
    "for face,eye1,eye2 in eyes:\n",
    " im.annotatePolygon(face.asPolygon(),\n",
    " width=4)\n",
    " im.annotatePoints([eye1,eye2])\n",
    "\n",
    "im.show(delay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: could not import fast_util.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-30fbf0f905c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyvision\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeDetector\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pyvision\\__init__.pyc\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexture\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlbp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_CLASSIC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_RAD1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_RAD2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_RAD3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_RAD4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLBP_RAD8\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbee\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparseSigSet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveSigset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcomputeMaskMatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBEE_CODE_MAP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBEE_DONTCARE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBEE_MATCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBEE_NONMATCH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBEEDistanceMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\pyvision\\analysis\\bee.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyvision\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mroc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'analysis'"
     ]
    }
   ],
   "source": [
    "import cv2.cv as cv\n",
    "import pyvision as pv\n",
    "import pyvision.face.CascadeDetector as cd\n",
    "\n",
    "\n",
    "detector = cd.CascadeDetector()\n",
    "\n",
    "cam = pv.Webcam()\n",
    "while True:\n",
    "    frame = cam.query()\n",
    "    rects = detector(frame)\n",
    "    for rect in rects:\n",
    "        frame.annotateRect(rect)\n",
    "    frame.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvision as pv\n",
    "import pyvision.face.CascadeDetector as cd\n",
    "\n",
    "detector = cd.CascadeDetector()\n",
    "\n",
    "cam = pv.Webcam()\n",
    "while True:\n",
    "    frame = cam.query()\n",
    "    rects = detector(frame)\n",
    "    for rect in rects:\n",
    "        frame.annotateRect(rect)\n",
    "    frame.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
